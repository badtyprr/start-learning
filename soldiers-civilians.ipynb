{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-grained classification practice with Flower-17\n",
    "\"\"\"\n",
    "\n",
    "# Python Packages\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "# 3rd Party Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import cv2\n",
    "# User Packages\n",
    "from start.preprocessing import ImageToTensorPreprocessor, ResizePreprocessor, ColorSpacePreprocessor\n",
    "from start.loader import ImageCachedDataset\n",
    "from start.model import MiniVGGNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing label: person\n",
      "[INFO] processed 80 person images\n",
      "[INFO] processed 160 person images\n",
      "[INFO] processed 240 person images\n",
      "[INFO] processed 320 person images\n",
      "[INFO] processed 400 person images\n",
      "[INFO] processed 480 person images\n",
      "[INFO] processed 560 person images\n",
      "[INFO] processed 640 person images\n",
      "[INFO] processed 720 person images\n",
      "[INFO] processed 800 person images\n",
      "[INFO] processed 880 person images\n",
      "[INFO] processed 960 person images\n",
      "[INFO] processed 1040 person images\n",
      "[INFO] Processing label: soldier\n",
      "[INFO] processed 80 soldier images\n",
      "[INFO] processed 160 soldier images\n",
      "[INFO] processed 240 soldier images\n",
      "[INFO] processed 320 soldier images\n",
      "[INFO] processed 400 soldier images\n",
      "[INFO] processed 480 soldier images\n",
      "[INFO] processed 560 soldier images\n",
      "[INFO] processed 640 soldier images\n",
      "[INFO] processed 720 soldier images\n",
      "[INFO] processed 800 soldier images\n",
      "[INFO] processed 880 soldier images\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-432635faa0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \"\"\"\n\u001b[1;32m     17\u001b[0m (data, labels) = dataset.load(\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Load Flowers-17 dataset\n",
    "dataset = ImageCachedDataset(\n",
    "    preprocessors=[\n",
    "        ResizePreprocessor(224, 224, aspect_preserving=True),\n",
    "        ColorSpacePreprocessor(conversion=cv2.COLOR_BGR2GRAY),\n",
    "        ImageToTensorPreprocessor()\n",
    "    ],\n",
    "    dataset_path=r'T:\\temp\\simeon\\dataset\\custom'\n",
    ")\n",
    "dataset._ignored_labels.append('firearm')\n",
    "\"\"\"\n",
    "(data, labels) = dataset.load(\n",
    "    dataset_path=r'/home/share/dataset/flowers17',\n",
    "    verbosity=80\n",
    ")\n",
    "\"\"\"\n",
    "(data, labels) = dataset.load(\n",
    "    verbosity=80\n",
    ")\n",
    "\n",
    "classes = set(labels)\n",
    "\n",
    "print('data shape: {}'.format(data.shape))\n",
    "print('labels shape: {}'.format(labels.shape))\n",
    "print('classes: {}'.format(classes))\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "data = data.astype(np.float) / 255.0\n",
    "\n",
    "# Split into train and test sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(\n",
    "    data, labels,\n",
    "    test_size=0.2,\n",
    "    random_state=int(time.time()),\n",
    "    stratify=list(labels)\n",
    ")\n",
    "\n",
    "# Free up the memory\n",
    "del data\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup data splits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pycm\n",
    "\n",
    "N_EPOCHS = 35\n",
    "BATCH_SIZE = 32\n",
    "n_classes = len(classes)\n",
    "kfold_splits = 10 #empirical\n",
    "timestamp = time.time()\n",
    "\n",
    "# Instantiate the cross validator\n",
    "skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "\n",
    "# Convert output to either binarized one-hot vectors for categorical or 0/1 for binary\n",
    "if n_classes > 2:\n",
    "    lb = LabelBinarizer()\n",
    "    testY = lb.fit_transform(testY)\n",
    "else:\n",
    "    le = LabelEncoder()\n",
    "    testY = le.fit_transform(testY)\n",
    "    \n",
    "# Data augmentation\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "def create_model(n_classes, alpha=1.4):\n",
    "    # Initialize the optimizer and model\n",
    "    print('[INFO] compiling model...')\n",
    "    opt = SGD(lr=0.05)\n",
    "    properties = {\n",
    "        'width':    64,\n",
    "        'height':   64,\n",
    "        'channels': 3,\n",
    "        'classes':  len(classes)\n",
    "    }\n",
    "    #model = MiniVGGNet.build(properties)\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    model = Sequential()\n",
    "    model.add(MobileNetV2(\n",
    "        input_shape=(224, 224, 3),\n",
    "        alpha=alpha, \n",
    "        depth_multiplier=1, \n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_tensor=None, \n",
    "        pooling='avg'\n",
    "    ))\n",
    "\n",
    "    if n_classes > 2:\n",
    "        model.add(Dense(\n",
    "            units=n_classes,\n",
    "            activation='softmax',\n",
    "            use_bias=True,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='glorot_uniform',\n",
    "            kernel_regularizer=None,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=None,\n",
    "            kernel_constraint=None,\n",
    "            bias_constraint=None\n",
    "        ))\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    # Hot dog or not hot dog\n",
    "    else:\n",
    "        model.add(Dense(\n",
    "            units=1,\n",
    "            activation='sigmoid',\n",
    "            use_bias=True,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='glorot_uniform',\n",
    "            kernel_regularizer=None,\n",
    "            bias_regularizer=None,\n",
    "            activity_regularizer=None,\n",
    "            kernel_constraint=None,\n",
    "            bias_constraint=None\n",
    "        ))\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "#model = create_model(n_classes=n_classes)\n",
    "from start.model import MobileNetV2\n",
    "model = MobileNetV2.build({\n",
    "    'width':    224,\n",
    "    'height':   224,\n",
    "    'channels': 1,\n",
    "    'weights': 'imagenet',\n",
    "    'dense_units': 242,\n",
    "    'dropout_rate': 0.43,\n",
    "    'regularization_strength': 0.0001\n",
    "})\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(skf.split(trainX, trainY)):\n",
    "    print('Training on fold {}/{}'.format(index, kfold_splits))\n",
    "    # Partition into train and test splits\n",
    "    \"\"\"\n",
    "    (valX, testX, valY, testY) = train_test_split(\n",
    "        testX, testY,\n",
    "        test_size=0.4,\n",
    "        random_state=int(time.time()),\n",
    "        stratify=list(testY)\n",
    "    )\n",
    "    \"\"\"\n",
    "    trainSplitX, valSplitX = trainX[train_indices], trainX[val_indices]\n",
    "    trainSplitY, valSplitY = trainY[train_indices], trainY[val_indices]\n",
    "    \n",
    "    # Convert output to either binarized one-hot vectors for categorical or 0/1 for binary\n",
    "    if n_classes > 2:\n",
    "        trainSplitY = lb.fit_transform(trainSplitY)\n",
    "        valSplitY = lb.fit_transform(valSplitY)\n",
    "    else:\n",
    "        trainSplitY = le.fit_transform(trainSplitY)\n",
    "        valSplitY = le.fit_transform(valSplitY)\n",
    "\n",
    "    # Initialize TensorBoard\n",
    "    \"\"\"\n",
    "    tb_callback = TensorBoard(\n",
    "        log_dir='./logs/splitindex{}'.format(index), \n",
    "        histogram_freq=1, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        write_graph=False, \n",
    "        write_grads=False, \n",
    "        write_images=False, \n",
    "        embeddings_freq=0,\n",
    "        embeddings_layer_names=None, \n",
    "        embeddings_metadata=None, \n",
    "        embeddings_data=None\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Train the network\n",
    "    print('[INFO] training network split {}...'.format(index))\n",
    "    callbacks = []\n",
    "    try:\n",
    "        if tb_callback is not None:\n",
    "            callbacks.append(tb_callback)\n",
    "    except NameError:\n",
    "        pass\n",
    "    history = model.fit_generator(\n",
    "        augmenter.flow(trainSplitX, trainSplitY, \n",
    "                       batch_size=BATCH_SIZE),\n",
    "        validation_data=(valSplitX, valSplitY),\n",
    "        steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "        epochs=N_EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "            \n",
    "    # Evaluate the network\n",
    "    print('[INFO] evaluating network split {}...'.format(index))\n",
    "    predictions = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "    if not n_classes > 2:\n",
    "        threshold = 0.5\n",
    "        predictions_probability = predictions\n",
    "        predictions[predictions>threshold] = 1\n",
    "        predictions[predictions<=threshold] = 0\n",
    "        predictions = predictions.astype(np.int)\n",
    "        \n",
    "\n",
    "    if n_classes > 2:\n",
    "        cm = pycm.ConfusionMatrix(\n",
    "            actual_vector=lb.inverse_transform(testY),\n",
    "            predict_vector=lb.inverse_transform(predictions)\n",
    "        )\n",
    "    else:\n",
    "        cm = pycm.ConfusionMatrix(\n",
    "            actual_vector=le.inverse_transform(testY),\n",
    "            predict_vector=le.inverse_transform(predictions)\n",
    "        )\n",
    "    cm.save_html(r'T:\\temp\\simeon\\dataset\\{}_confusion_matrix_splitindex{}'.format(timestamp, index))\n",
    "\n",
    "    # Plot the training loss and accuracy\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N_EPOCHS), history.history['loss'], label='train_loss')\n",
    "    plt.plot(np.arange(0, N_EPOCHS), history.history['val_loss'], label='val_loss')\n",
    "    plt.plot(np.arange(0, N_EPOCHS), history.history['acc'], label='train_acc')\n",
    "    plt.plot(np.arange(0, N_EPOCHS), history.history['val_acc'], label='val_acc')\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(r'T:\\temp\\simeon\\dataset\\{}_training_splitindex{}.jpg'.format(timestamp, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "predictions = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "if not n_classes > 2:\n",
    "    threshold = 0.5\n",
    "    predictions_probability = predictions.copy()\n",
    "    predictions[predictions>threshold] = 1\n",
    "    predictions[predictions<=threshold] = 0\n",
    "    predictions = predictions.astype(np.int)\n",
    "\n",
    "# Plot images that were soldiers classified as people\n",
    "print('classes: {}'.format(classes))\n",
    "print('testY shape: {}'.format(testY.shape))\n",
    "print('predictions shape: {}'.format(predictions.shape))\n",
    "soldiers_classified_people = testX[np.logical_and(testY == 1, np.squeeze(predictions) == 0)]\n",
    "try:\n",
    "    probability = predictions_probability[np.logical_and(testY == 1, np.squeeze(predictions) == 0)]\n",
    "except NameError:\n",
    "    pass\n",
    "print('soldiers_classified_people shape: {}'.format(soldiers_classified_people.shape))\n",
    "print('probability shape: {}'.format(probability.shape))\n",
    "print('probability: \\n{}'.format(probability))\n",
    "# Draw figure\n",
    "if soldiers_classified_people.shape[0] > 0:\n",
    "    IMAGES_PER_ROW = 4\n",
    "    rows = (soldiers_classified_people.shape[0] // IMAGES_PER_ROW) + 1\n",
    "    f = plt.figure(\n",
    "        num=1, \n",
    "        figsize=(14, int(14*rows/float(IMAGES_PER_ROW))), \n",
    "        dpi=80, \n",
    "        facecolor='w', \n",
    "        edgecolor='k'\n",
    "    )\n",
    "    print('{} x {} plot'.format(rows, IMAGES_PER_ROW))\n",
    "    for subidx in range(soldiers_classified_people.shape[0]):\n",
    "        # subplot is 1-indexed\n",
    "        plt.subplot(rows, IMAGES_PER_ROW, subidx+1)\n",
    "        f.gca().grid(False)\n",
    "        try:\n",
    "            plt.title('Soldier: {0:.2f}%'.format(np.asscalar(probability[subidx])*100.0))\n",
    "        except NameError:\n",
    "            pass\n",
    "        plt.imshow(soldiers_classified_people[subidx][..., ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network\n",
    "predictions = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "if not n_classes > 2:\n",
    "    threshold = 0.5\n",
    "    predictions_probability = predictions.copy()\n",
    "    predictions[predictions>threshold] = 1\n",
    "    predictions[predictions<=threshold] = 0\n",
    "    predictions = predictions.astype(np.int)\n",
    "\n",
    "# Plot images that were people classified as soldiers\n",
    "print('classes: {}'.format(classes))\n",
    "print('testY shape: {}'.format(testY.shape))\n",
    "print('predictions shape: {}'.format(predictions.shape))\n",
    "people_classified_soldiers = testX[np.logical_and(testY == 0, np.squeeze(predictions) == 1)]\n",
    "try:\n",
    "    probability = predictions_probability[np.logical_and(testY == 0, np.squeeze(predictions) == 1)]\n",
    "except NameError:\n",
    "    pass\n",
    "print('people_classified_soldiers shape: {}'.format(people_classified_soldiers.shape))\n",
    "print('probability shape: {}'.format(probability.shape))\n",
    "print('probability: \\n{}'.format(probability))\n",
    "# Draw figure\n",
    "if people_classified_soldiers.shape[0] > 0:\n",
    "    IMAGES_PER_ROW = 4\n",
    "    rows = (people_classified_soldiers.shape[0] // IMAGES_PER_ROW) + 1\n",
    "    f = plt.figure(\n",
    "        num=2, \n",
    "        figsize=(14, int(14*rows/float(IMAGES_PER_ROW))), \n",
    "        dpi=80, \n",
    "        facecolor='w', \n",
    "        edgecolor='k'\n",
    "    )\n",
    "    print('{} x {} plot'.format(rows, IMAGES_PER_ROW))\n",
    "    for subidx in range(people_classified_soldiers.shape[0]):\n",
    "        # subplot is 1-indexed\n",
    "        plt.subplot(rows, IMAGES_PER_ROW, subidx+1)\n",
    "        f.gca().grid(False)\n",
    "        try:\n",
    "            plt.title('Person: {0:.2f}%'.format(np.asscalar(1.0-probability[subidx])*100.0))\n",
    "        except NameError:\n",
    "            pass\n",
    "        plt.imshow(people_classified_soldiers[subidx][..., ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model!\n",
    "model.save_weights(r'T:\\temp\\simeon\\dataset\\{}_mnv2_soldier-person_StratifiedKFold10_weights.h5'.format(timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
